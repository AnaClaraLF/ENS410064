





import pandas as pd
import numpy as np
import math
from matplotlib import pyplot as plt

#load the data set into a pandas data frame
df = pd.read_csv('D:/ENS410064/Dados/brutos/retail_sales_used_car_dealers_us_1992_2020.csv', header=0, index_col=0, 
                 parse_dates=['DATE'], date_format={'DATE': '%Y-%m-%d'})

#plot the data set
fig = plt.figure()
fig.suptitle('Retail sales of used car dealers in the US in millions of dollars')
df['Retail_Sales'].plot()
plt.show()




#add a column containing a 2 x 12 centered moving average. this column will capture the trend component in the time series
df['2 x 12 CMA (TREND)'] = np.nan
for i in range(6,df['Retail_Sales'].size-6):
    df['2 x 12 CMA (TREND)'].iloc[i] = df['Retail_Sales'].iloc[i-6] * 1.0 / 24 + (
                df['Retail_Sales'].iloc[i-5] + df['Retail_Sales'].iloc[i-4] + df['Retail_Sales'].iloc[i-3] + df['Retail_Sales'].iloc[
            i-2] + df['Retail_Sales'].iloc[i-1] + df['Retail_Sales'].iloc[i] + df['Retail_Sales'].iloc[i + 1] + df['Retail_Sales'].iloc[
                    i + 2] + df['Retail_Sales'].iloc[i + 3] + df['Retail_Sales'].iloc[i + 4] + df['Retail_Sales'].iloc[
                    i + 5]) * 1.0 / 12 + df['Retail_Sales'].iloc[i + 6] * 1.0 / 24
# tem que usar iloc pra funcionar

#plot the trend component
fig = plt.figure()
fig.suptitle('TREND component of Retail sales of used car dealers in the US in millions of dollars')
df['2 x 12 CMA (TREND)'].plot()
plt.show()



df['SEASONALITY AND NOISE'] = df['Retail_Sales']/df['2 x 12 CMA (TREND)']

#plot the seasonality and noise components
fig = plt.figure()
fig.suptitle('SEASONALITY and NOISE components')
plt.ylim(0, 1.3)
df['SEASONALITY AND NOISE'].plot()
plt.show()


#calculate the average seasonal component for each month

#first add a month column
df['MONTH'] = df.index.strftime('%m').astype(np.int64)

#initialize the month based dictionaries to store the running total of themonth wise  seasonal sums and counts
average_seasonal_values = {1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0, 10:0, 11:0, 12:0}
average_seasonal_value_counts = {1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0, 10:0, 11:0, 12:0}

#calculate the sums and counts
for i in range(0, df['SEASONALITY AND NOISE'].size):
    if math.isnan(df['SEASONALITY AND NOISE'].iloc[i]) is False:
        average_seasonal_values[df['MONTH'].iloc[i]] = average_seasonal_values[df['MONTH'].iloc[i]] + df['SEASONALITY AND NOISE'].iloc[i]
        average_seasonal_value_counts[df['MONTH'].iloc[i]] = average_seasonal_value_counts[df['MONTH'].iloc[i]] + 1

#calculate the average seasonal component for each month
for i in range(1, 13):
    average_seasonal_values[i] = average_seasonal_values[i] / average_seasonal_value_counts[i]



pd.set_option('mode.chained_assignment', None) # suprimir os avisos, mas nao resolve o problema
#create a new column in the data frame and fill it with the value of the average seasonal component for the corresponding month
df['SEASONALITY'] = np.nan
for i in range(0, df['SEASONALITY AND NOISE'].size):
    if math.isnan(df['SEASONALITY AND NOISE'].iloc[i]) is False:
        df['SEASONALITY'].iloc[i] = average_seasonal_values[df['MONTH'].iloc[i]]




#plot the seasonal component
fig = plt.figure()
fig.suptitle('The \'Pure\' SEASONAL component')
plt.ylim(0, 1.3)
df['SEASONALITY'].plot()
plt.show()




df['NOISE'] = df['SEASONALITY AND NOISE']/df['SEASONALITY']

#plot the seasonal component
fig = plt.figure()
fig.suptitle('The NOISE component')
plt.ylim(0, 1.3)
df['NOISE'].plot()
plt.show()



#Do all of the above using  one line of code!
from statsmodels.tsa.seasonal import seasonal_decompose
components = seasonal_decompose(df['Retail_Sales'], model='multiplicative')
components.plot()
plt.show()





del(dfbal,bal)


from statsmodels.tsa.seasonal import seasonal_decompose
import pandas as pd
import numpy as np
import math
from matplotlib import pyplot as plt

#load the data set into a pandas data frame
#dfbal = pd.read_csv('C:/Users/anafranco/Documents/ENS410064/balnBCfill.csv', header=0, index_col=0, 
dfbal = pd.read_csv('d:/ENS410064/Dados/brutos/IMA/balnBCfill.csv', header=0, index_col=0, 
                 parse_dates=['DATA'], date_format={'DATA': '%d/%m/%Y'})

print(dfbal.index) #confere que a coluna de data é indice
dfbal.sort_index(inplace=True) # ordena datas



# escolher um ponto para analisar
bal = dfbal[dfbal['PONTO']== 1]

#plot the data set
fig = plt.figure()
fig.suptitle('temp da agua')
bal['tagua'].plot()
plt.show()




# aplicar a temperatura do ar, que é sazonal, para testar 
components = seasonal_decompose(bal['tar'], model='aditive', period=50) 
components.plot()
plt.show()

# period set to 50, pq e mais ou menos o numero de coletas por ano. A frequencia nao e homogenea e por isso e necessario informar o periodo dos dados.
# mesmo com o indice sendo datatimeIndex, a funcao nao conseguiu identificar o periodo/frequencia sozinha, provavelmente pq os dados possuem frequencia muito aleatoria.
# components = seasonal_decompose(bal.asfreq('D')['ecoli'] )
# a funcao nao sabe lidar com falhas (NaNs) e por isso nao adianta construir uma serie diária homogenea
# a lot about this is explained on - https://stackoverflow.com/questions/60017052/decompose-for-time-series-valueerror-you-must-specify-a-period-or-x-must-be/63252466



components = seasonal_decompose(bal['ecoli'], period=50)
components.plot()
plt.show()









import statsmodels.graphics.tsaplots as tsa
 
tsa.plot_acf(bal['ecoli'], lags=40, alpha=0.05, title='Auto-correlation coefficients for lags 1 through 40')


tsa.plot_acf(bal['tagua'], lags=100, alpha=0.05, title='Auto-correlation coefficients for lags 1 through 100')








import statsmodels.stats.diagnostic as diag
 
diag.acorr_ljungbox(dfbal['ecoli'], lags=[1], boxpierce=True, model_df=0, period=None, return_df=None)


diag.acorr_ljungbox(dfbal['tagua'], lags=[2], boxpierce=True, model_df=0, period=None, return_df=None)








# we create a new data set with Y = Y_i —Y_(i-1) :
diff_Y_iecoli = dfbal['ecoli'].diff()
#drop the NAN in the first row
diff_Y_iecoli = diff_Y_iecoli.dropna()
 
#Let’s plot the diff-ed data set
diff_Y_iecoli.plot()
plt.show()


# we create a new data set with Y = Y_i —Y_(i-1) :
diff_Y_itagua = dfbal['tagua'].diff()
#drop the NAN in the first row
diff_Y_itagua = diff_Y_itagua.dropna()
 
#Let’s plot the diff-ed data set
diff_Y_itagua.plot()
plt.show()


# nao parecem ser ruidos branco, mas vamos fazer o teste na diferenca
diag.acorr_ljungbox(diff_Y_iecoli, lags=[40], boxpierce=True)



diag.acorr_ljungbox(diff_Y_itagua, lags=[40], boxpierce=True)








import pandas as pd
from patsy import dmatrices
from matplotlib import pyplot as plt
import numpy as np




dfbal


dfbal.plot.scatter(x='tar', y='tagua') # confere se os registros de temperatura estao OK
plt.xlabel('temp do ar', fontsize=18)
plt.ylabel('temp da agua', fontsize=18)
plt.show()



dfbal.plot.scatter(x='ecoli', y='tagua') # procura correlacao entre temp agua e densidade de ecoli
plt.xlabel('ecoli NMP 100mL', fontsize=18)
plt.ylabel('temp da agua', fontsize=18)
plt.show()



dfbal.corr(numeric_only='True')['ecoli'] # estima o coef de correlacao das variaveis numeric only com Ecoli





bal_p=dfbal
# substituir texto para numero para correlacionar chuva anterior ?
# chuva- ausente =0; fraca = 1; moderada = 2; intensa=3
bal_p.replace(['AUSENTE','FRACA','MODERADA','INTENSA'],[0 , 1 , 2 , 3], inplace=True)
bal_p['CHUVAult24HR'] = bal_p['CHUVAult24HR'].fillna(0) # preenche falha tb
bal_p




bal_p.plot.scatter(x='ecoli', y='CHUVAult24HR')
plt.xlabel('ecoli NMP 100mL', fontsize=18)
plt.ylabel('chuva nas ultimas 24h', fontsize=18)
plt.show()






from patsy import dmatrices, dmatrix, demo_data
from statsmodels.regression import linear_model

model_expr = 'ecoli ~ tagua + tar + CHUVAult24HR'
y, X = dmatrices(model_expr, bal_p, return_type='dataframe')

# The training data set will be 80% of the size of the overall (y, X) and the rest will be the testing data set:
mask = np.random.rand(len(X)) < 0.8
X_train = X[mask]
y_train = y[mask]
X_test = X[~mask]
y_test = y[~mask]

olsr_results = linear_model.OLS(y_train, X_train).fit()
print('Training completed')
 
print(olsr_results.summary())


# agora com os dados de test
olsr_predictions = olsr_results.get_prediction(X_test)
prediction_summary_frame = olsr_predictions.summary_frame()
print(prediction_summary_frame)


#Let’s calculate the residual errors of regression ε = (y_test — y_pred):
resid = y_test['ecoli'] - prediction_summary_frame['mean']

#Finally, let’s plot resid against the predicted value y_pred=prediction_summary_frame[‘mean’]:
plt.xlabel('Predicted ecoli', fontsize=18)
plt.ylabel('Residual Error of Regression', fontsize=18)
plt.scatter(y_test['ecoli'], resid)








from statsmodels.compat import lzip
import statsmodels.stats.api as sms
 
name = ['Jarque-Bera test', 'Chi-squared(2) p-value', 'Skewness', 'Kurtosis']
 
#run the Jarque-Bera test for Normality on the residuals vector
test = sms.jarque_bera(resid)
 
#print out the test results. This will also print the Skewness and Kurtosis of the resid vector
lzip(name, test)





resid.hist(bins=50)
plt.show()





from statsmodels.stats.diagnostic import het_white
 
keys = ['Lagrange Multiplier statistic:', 'LM test\'s p-value:', 'F-statistic:', 'F-test\'s p-value:']
 
#run the White test
results = het_white(resid, X_test)
 
#print the results. We will get to see the values of two test-statistics and the corresponding p-values
lzip(keys, results)






